{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Machine Learning With Python [Part - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In <a href=\"https://savan77.github.io/blog/machine-learning-part1.html\">this part</a>, we discussed about what is machine learning, types of machine learning, linear regression, logistic regression, cross validation and overfitting. In this lab session, I will demonstrate these concepts in Python code. Python is widely used programming language in the field of scientific computing. And the reason is the awesome libraries such as numpy, scikit-learn, matplotlib, etc. We are also going to use these libraries in the lab sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with very simple algorithm called Linear Regression. In the <a href=\"https://savan77.github.io/blog/machine-learning-part1.html\">blog post</a>, I explained in-depth - what is linear regression and how it works. In this session, we will focus on implementation rather than theory. We will follow the standard procedure of training machine learning models.\n",
    "<ul>\n",
    "    <li> Load the dataset</li>\n",
    "    <li> Preprocess/Augment the dataset </li>\n",
    "    <li> Train a model</li>\n",
    "    <li> Test a model </li>\n",
    "    <li> Deploy a model</li>\n",
    "</ul>\n",
    "\n",
    "In practice, most of the time we spent behind getting dataset ready for a model, that is, preprocessing and all stuff. Here, I will use preprocessed dataset.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a python library called <b> scikit-learn</b> which is the widely used machine learning lib. For installation process please visit - <a href=\"http://scikit-learn.org\">scikit-learn website</a>. You can install it with pip - <i> pip install -U scikit-learn</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "#sklearn comes with few small datasets. We will use one of them called \"boston housing\". Which is identical to\n",
    "#to the example we saw in theory part. This dataset has 506 samples with 13 features (columns). Here target variable\n",
    "#is the price of the house.\n",
    "\n",
    "#import the libs\n",
    "from sklearn.datasets import load_boston\n",
    "#load the dataset\n",
    "data = load_boston()  #returns dictionary-like object, attributes are - data, target, DESCR\n",
    "#first of all, let's see the shape of the training data\n",
    "print(data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "#shape of a target/labels\n",
    "print(data.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#important info about the dataset\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24. ,  21.6,  34.7,  33.4,  36.2,  28.7,  22.9,  27.1,  16.5,\n",
       "        18.9,  15. ,  18.9,  21.7,  20.4,  18.2,  19.9,  23.1,  17.5,\n",
       "        20.2,  18.2,  13.6,  19.6,  15.2,  14.5,  15.6,  13.9,  16.6,\n",
       "        14.8,  18.4,  21. ,  12.7,  14.5,  13.2,  13.1,  13.5,  18.9,\n",
       "        20. ,  21. ,  24.7,  30.8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how target values look like\n",
    "data.target[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this dataset is already preprocessed, we dont have to anything in this phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#create a linear regression object\n",
    "lin_reg = LinearRegression()\n",
    "#train a model\n",
    "lin_reg.fit(data.data, data.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.07170557e-01,   4.63952195e-02,   2.08602395e-02,\n",
       "         2.68856140e+00,  -1.77957587e+01,   3.80475246e+00,\n",
       "         7.51061703e-04,  -1.47575880e+00,   3.05655038e-01,\n",
       "        -1.23293463e-02,  -9.53463555e-01,   9.39251272e-03,\n",
       "        -5.25466633e-01])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learned weights\n",
    "lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.491103280363134"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learned intercept\n",
    "lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Test a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27.94288232])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use a model to predict as follows\n",
    "lin_reg.predict(data.data[4].reshape(1,-1))  #first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.200000000000003"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see what was the true value\n",
    "data.target[4]  #not good :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.897779217687496"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(data.target, lin_reg.predict(data.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.897779217687496"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us calculate mse from scratch to make sure its correct\n",
    "import numpy as np\n",
    "np.mean((lin_reg.predict(data.data) - data.target) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Deploy a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use <b> predict</b> method to predict the price of a house."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the main benifit of these libraries are we do not have to worry about internal algorithms. It does this work for us. Later in this session, I will make some visualization to make concepts more clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is the classification algorithm. In the theory session, I explained how it works. Sigmoid function is the core of this algorithm. We can implement this function in numpy as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-20.        , -19.18367347, -18.36734694, -17.55102041,\n",
       "       -16.73469388, -15.91836735, -15.10204082, -14.28571429,\n",
       "       -13.46938776, -12.65306122, -11.83673469, -11.02040816,\n",
       "       -10.20408163,  -9.3877551 ,  -8.57142857,  -7.75510204,\n",
       "        -6.93877551,  -6.12244898,  -5.30612245,  -4.48979592,\n",
       "        -3.67346939,  -2.85714286,  -2.04081633,  -1.2244898 ,\n",
       "        -0.40816327,   0.40816327,   1.2244898 ,   2.04081633,\n",
       "         2.85714286,   3.67346939,   4.48979592,   5.30612245,\n",
       "         6.12244898,   6.93877551,   7.75510204,   8.57142857,\n",
       "         9.3877551 ,  10.20408163,  11.02040816,  11.83673469,\n",
       "        12.65306122,  13.46938776,  14.28571429,  15.10204082,\n",
       "        15.91836735,  16.73469388,  17.55102041,  18.36734694,\n",
       "        19.18367347,  20.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = np.linspace(-20,20,50) #generate a list of numbers\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.        ,  0.99999999,  0.99999998,  0.99999995,\n",
       "        0.99999988,  0.99999972,  0.99999938,  0.99999859,  0.9999968 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will pass each number through sigmoid function\n",
    "results = sigmoid(numbers)\n",
    "results[:10]  #print few numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, all numbers are squashed between [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will implement logistic regression using sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAACTCAYAAADbeI0aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b7da025a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this time we will use digit dataset.\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data  #input\n",
    "y = digits.target #output\n",
    "print(digits.data.shape)  #1797 samples * 64 (8*8)pixels\n",
    "#input is an image and we would like to train a model which can predict the digit that image contains\n",
    "#each image is of 8 * 8 pixels\n",
    "\n",
    "#plot few digits  ## dont worry if u dont understand it\n",
    "fig = plt.figure()\n",
    "plt.gray()\n",
    "ax1 = fig.add_subplot(231)\n",
    "ax1.imshow(digits.images[0])\n",
    "\n",
    "ax2 = fig.add_subplot(232)\n",
    "ax2.imshow(digits.images[1])\n",
    "\n",
    "ax3 = fig.add_subplot(233)\n",
    "ax3.imshow(digits.images[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we dont need to preprocess our dataset, we will directly move to third step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "#train a model\n",
    "log_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Test a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99332220367278801"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sklearn provides several ways to test a classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, log_reg.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99332220367278801"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another way\n",
    "log_reg.score( X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please recall that its not a good thing to test a model on training dataset. As you can see, we are getting almost 100% accuracy and the reason is we are testing a model on the dataset on which we trained it. Its like you got examples in your test paper same as you practiced during the lecture. So, deifnitely you will get full marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[178,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0, 179,   0,   1,   0,   0,   0,   0,   2,   0],\n",
       "       [  0,   0, 177,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0, 183,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0, 181,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0, 182,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 181,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 179,   0,   0],\n",
       "       [  0,   5,   0,   1,   0,   0,   0,   0, 168,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   0,   0,   2, 177]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix is a table that can be used to evaluate the performance of a classifier\n",
    "#each row shows actual values and column values shows predicted values\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y, log_reg.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix is a table that can be used to evaluate the performance of a classifier. Each row shows actual values and column values shows predicted values. For example, image with digit 9 comes 180 times but our model predicted 177 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted :  [1]\n",
      "Actual :  1\n"
     ]
    }
   ],
   "source": [
    "#we can use predict method to predict the class\n",
    "print(\"Predicted : \" , log_reg.predict(digits.data[1].reshape(1,-1)))\n",
    "print(\"Actual : \", digits.target[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.75045461e-18   9.99447460e-01   7.00809699e-10   3.72475330e-09\n",
      "    2.15616661e-06   1.35167550e-09   5.71303497e-10   1.95595337e-13\n",
      "    5.50377100e-04   5.64607392e-10]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can also predict the probability of each class\n",
    "proba = log_reg.predict_proba(digits.data[1].reshape(1,-1)) # second column has the highest probability\n",
    "print(proba)\n",
    "np.argmax(proba) #please note index starts with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice,we divide our dataset into two parts-training and testing part. Lets implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris #https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
    "iris = load_iris()\n",
    "iris.data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split the dataset into two parts\n",
    "from sklearn.model_selection import train_test_split\n",
    "#split dataset into 70-30\n",
    "X_train, X_test, y_train , y_test = train_test_split(iris.data, iris.target, test_size= 0.3, random_state=42)\n",
    "#randomstate - to make sure each time we run this code it gives same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4)\n",
      "(105,)\n",
      "(45, 4)\n",
      "(45,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train on training data\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97777777777777775"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test on test data\n",
    "model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In theory part, I explained what is overfitting and how it might affect our model so badly. Next, we will implement various methods such as regularizarion and cross-validation to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, scikit-learn uses l2 regularization with C=1. Please note, C is the inverse of regularization strength. We can tweak some parameters to play around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97777777777777775"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(penalty=\"l2\", C=1) #default configuration\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test) #note, we got same accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us use l1 regularization\n",
    "model = LogisticRegression(penalty=\"l1\", C=1)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test) #whoa! we got 100% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91111111111111109"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(penalty=\"l2\", C=0.23)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test) \n",
    "\n",
    "#you have to consider various values for this type of parameters (hyperparameters) to find the best one\n",
    "# we can do this with GridCV, RandomCV- This is beyond the scope of this lab session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we discussed about k-fold cross validation. In which we divide whole dataset into k parts and each time we hold out\n",
    "#one part and train on k-1 parts\n",
    "\n",
    "#we'll use boston housing dataset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=5) #k=10\n",
    "\n",
    "costs = []\n",
    "for train_index,test_index in kfold.split(data.data):\n",
    "    X_train, y_train = data.data[train_index], data.target[train_index]\n",
    "    X_test, y_test = data.data[test_index], data.target[test_index]\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    costs.append(mean_squared_error(y_test, model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.222843637138403"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93102983468390121"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 fold cross-validation\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import cross_val_score\n",
    "digits = load_digits()\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "scores = cross_val_score(model,digits.data, digits.target, cv=10, scoring='accuracy' )\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For classification tasks, it is recommended to use variant of KFold- <b> StratifiedFold</b> which preserves the percentage of samples for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "digits = load_digits()\n",
    "skfold = StratifiedKFold(n_splits= 10)\n",
    "costs = []\n",
    "for train_index,test_index in skfold.split(digits.data, digits.target):\n",
    "    X_train, y_train = digits.data[train_index], digits.target[train_index]\n",
    "    X_test, y_test = digits.data[test_index], digits.target[test_index]\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    costs.append(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93102983468390121"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
