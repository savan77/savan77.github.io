
This invention presents a novel method for image search. Traditional method used by image search engines were not as accurate the method presented here. For example, you might have uploaded an image of Colosseum and you get search results related to Rome. In conclusion, this invention presents a novel and more accurate method for image search which is based on the discovery of semantic similarities between images and text.

This discovery introduces a method to discover a semantic similarity between image and text. Ultimately, proposing a novel method for image search. Upon receiving an image, the system invokes the deep multimodel similarity model to generate image vector and several text vector relevant to the image. Then, the system comapres the image vector with all text vectors and determines the most relevant text vector. This text vector later can be used by search engine algorithm to retrive search result.

A method to determine the semantic similarity between image and text is disclosed herein. Which can be used for performing image search using textual query and performing text search using an image as a query. The system generates a caption using a caption generator. Caption generator generates several captions for an image and then a semantic similarity model identifies the best caption. The similarity can be determined by projecting text vectors and image vector in a semantic space.

A caption generation model which upon receving an image, generates a text relevant to an image;
How image search engine works;
A semantic space where vectors can be mapped to determine the similarity.

The presented method describes a way to determine similarity between images and text, which can be used in image to text and text to image search engine. However, we might extend this method for image to image as well. Given an image as input, we first find the image vector of given image and compare this to the database. Similarity of these vectors can be measured by projecting them in semantic space.


We completed our work on design engineering canvases. We also started working on the first module of our prototype-image caption generation. We are using a combination of convolutional neural network and recurrent neural network for this module. Also, we are developing most of our modules in Python using libraries such as TensorFlow, Keras, numpy and scikit-learn.

Our experience of TensorFlow helped us so much, but recent changes in TensorFlow resulted in some bugs and errors. We were learning about latest changes in TensorFlow to make ourselves acquainted with these changes.

Since our models need to be trained on large datasets, we need computational resources(GPUs) to train our deep learning models.

We were referring to various design engineering literature to complete the canvases. We also referred some research papers to learn state-of-the-art techniques in image caption generation. For tensorflow, we were using various online resources.18602679999

1504881447